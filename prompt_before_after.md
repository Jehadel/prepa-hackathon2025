# Exemples Avant/Apr√®s : Optimisation de Prompts

## üéØ Guide de lecture

Pour chaque exemple :
- ‚ùå **AVANT** : Le prompt probl√©matique
- ‚ö†Ô∏è **PROBL√àMES** : Ce qui ne va pas
- ‚úÖ **APR√àS** : Le prompt optimis√©
- üí° **POURQUOI C'EST MIEUX** : Les am√©liorations apport√©es
- üìä **IMPACT** : Diff√©rence dans la qualit√© de r√©ponse

---

## Exemple 1 : Question vague sur le chargement de donn√©es

### ‚ùå AVANT
```
comment charger un csv en python
```

### ‚ö†Ô∏è PROBL√àMES
- Trop vague et g√©n√©rique
- Aucun contexte sur le CSV (taille, probl√®mes, contraintes)
- Pas d'indication sur le niveau de d√©tail souhait√©
- L'IA va donner une r√©ponse "tutoriel d√©butant"

### ‚úÖ APR√àS
```markdown
## Contexte
- Python 3.11, pandas 2.1
- CSV de 3 Go avec 50 colonnes
- S√©parateur : point-virgule
- Encoding : latin-1
- Probl√®me : RAM limit√©e √† 8 Go

## Objectif
Charger ce CSV sans saturer la m√©moire

## Question
Quelle approche recommandes-tu ? 
Options : chunksize, colonnes s√©lectives, ou autre ?
```

### üí° POURQUOI C'EST MIEUX
- Contexte technique pr√©cis (versions, taille)
- Probl√©matique claire (contrainte RAM)
- Sp√©cificit√©s du CSV mentionn√©es
- Question cibl√©e avec options envisag√©es

### üìä IMPACT
- **Avant** : R√©ponse g√©n√©rique `pd.read_csv('file.csv')`
- **Apr√®s** : Code optimis√© avec `usecols`, `dtype`, `chunksize` et comparaison des approches

---

## Exemple 2 : Debugging sans contexte

### ‚ùå AVANT
```
j'ai une erreur avec mon code pandas aide moi

df.merge(df2)
```

### ‚ö†Ô∏è PROBL√àMES
- Pas de message d'erreur fourni
- Contexte des DataFrames absent (colonnes, types)
- Code incomplet (comment sont cr√©√©s df et df2 ?)
- Pas d'explication de l'objectif du merge

### ‚úÖ APR√àS
```markdown
## Probl√®me
Erreur lors d'un merge de deux DataFrames pandas

## Erreur compl√®te
ValueError: You are trying to merge on object and int64 columns

## Code
```python
df_sales = pd.read_csv('sales.csv')
df_customers = pd.read_csv('customers.csv')
result = pd.merge(df_sales, df_customers, on='customer_id')

## Structure des donn√©es
df_sales :
- customer_id : dtype object, exemples : "C001", "C002", "C003"
- amount : float64
- date : datetime64

df_customers :
- customer_id : dtype int64, exemples : 1, 2, 3
- name : object
- region : object

## Objectif
Joindre les ventes avec les infos clients pour enrichir l'analyse

## Question
Comment r√©soudre cette incoh√©rence de types sur la cl√© de jointure ?
```
### üí° POURQUOI C'EST MIEUX
- Message d'erreur complet fourni
- Code contextuel (pas juste la ligne qui plante)
- Structure d√©taill√©e des DataFrames avec exemples de valeurs
- Objectif m√©tier explicit√©
- Question pr√©cise

### üìä IMPACT
- **Avant** : L'IA devine qu'il y a un probl√®me de types (mais lequel ?)
- **Apr√®s** : Solution pr√©cise avec explication du probl√®me d'incoh√©rence format string vs int, et 3 approches de r√©solution

## Exemple 3 : Choix de mod√®le trop g√©n√©ral

### ‚ùå AVANT

```
quel mod√®le de machine learning utiliser pour mon projet ?
```

### ‚ö†Ô∏è PROBL√àMES
- Aucune info sur le type de probl√®me (classification, r√©gression, etc.)
- Pas de d√©tails sur les donn√©es
- Contraintes inconnues
- L'IA ne peut que lister tous les mod√®les possibles

### ‚úÖ APR√àS
```markdown
## Contexte du projet
Pr√©diction du churn client pour une plateforme SaaS B2B

## Donn√©es
- Volume : 50k clients (historique 2 ans)
- Features : 35 colonnes
  - 20 num√©riques : m√©triques d'usage (logins/mois, features utilis√©es, tickets support)
  - 10 cat√©gorielles : plan tarifaire, industrie, taille entreprise
  - 5 temporelles : anciennet√©, derni√®re connexion, date dernier paiement
- Cible : Churn dans les 3 prochains mois (binaire)
- D√©s√©quilibre : 80% r√©tention, 20% churn

## Objectifs m√©tier
- Priorit√© : **Recall √©lev√©** (on veut d√©tecter un maximum de churners)
- Precision acceptable : > 40% (pour limiter les faux positifs)
- **Explicabilit√© importante** : √©quipe m√©tier doit comprendre les pr√©dictions

## Contraintes techniques
- Inf√©rence : batch quotidien (pas de temps r√©el)
- Temps d'entra√Ænement : peut aller jusqu'√† quelques heures
- D√©ploiement : environnement Python standard (sklearn, xgboost OK)

## Question
Quels mod√®les recommandes-tu pour ce cas d'usage ? 
Peux-tu comparer 3-4 options avec leurs avantages/inconv√©nients 
en tenant compte de mes contraintes ?
```

### üí° POURQUOI C'EST MIEUX
- Type de probl√®me clair (classification binaire d√©s√©quilibr√©e)
- Caract√©ristiques des donn√©es d√©taill√©es
- Contraintes m√©tier explicites (recall vs precision, explicabilit√©)
- Contraintes techniques pr√©cis√©es
- Demande structur√©e (comparaison de plusieurs options)

### üìä IMPACT
- **Avant** : Liste g√©n√©rique de mod√®les sans justification
- **Apr√®s** : Recommandation cibl√©e (ex : XGBoost, Random Forest, LightGBM) avec analyse comparative bas√©e sur les crit√®res explicabilit√©/performance, param√®tres sugg√©r√©s, et plan de mise en ≈ìuvre

---

## Exemple 4 : Optimisation de code sans contexte

### ‚ùå AVANT
```
mon code est trop lent comment acc√©l√©rer

for i in range(len(df)):
    df.loc[i, 'new'] = df.loc[i, 'a'] * 2
```

### ‚ö†Ô∏è PROBL√àMES
- Taille du DataFrame inconnue (1000 lignes ou 10 millions ?)
- Pas d'info sur la complexit√© r√©elle du calcul
- Environnement et ressources non pr√©cis√©s
- D√©finition de "trop lent" absente (2 secondes ou 2 heures ?)

### ‚úÖ APR√àS
~~~markdown
## Probl√®me de performance
Traitement trop lent sur un DataFrame pandas

## Contexte
- DataFrame : 5 millions de lignes, 30 colonnes
- Environnement : serveur 32 Go RAM, 8 CPU cores
- Temps actuel : 45 minutes
- Objectif : < 5 minutes

## Code actuel

```python
# Calcul d'un score composite bas√© sur plusieurs conditions
for i in range(len(df)):
    if df.loc[i, 'type'] == 'premium':
        if df.loc[i, 'usage'] > 1000:
            df.loc[i, 'score'] = df.loc[i, 'base_score'] * 1.5
        else:
            df.loc[i, 'score'] = df.loc[i, 'base_score'] * 1.2
    elif df.loc[i, 'type'] == 'standard':
        df.loc[i, 'score'] = df.loc[i, 'base_score'] * 0.9
    else:
        df.loc[i, 'score'] = df.loc[i, 'base_score']
```
## Ce que j'ai d√©j√† essay√©
- `df.apply()` avec axis=1 ‚Üí encore plus lent (52 minutes)
- R√©duction du DataFrame ‚Üí m√™me probl√®me sur subset

## Question
Comment vectoriser ce calcul avec numpy/pandas ?
Y a-t-il d'autres approches (Dask, numba, parall√©lisation) ?

~~~

### üí° POURQUOI C'EST MIEUX
- √âchelle du probl√®me quantifi√©e (5M lignes, 45 min)
- Code complet avec la logique m√©tier
- Objectif de performance chiffr√©
- Tentatives pr√©c√©dentes document√©es
- Ressources disponibles pr√©cis√©es
- Questions sp√©cifiques sur les approches

### üìä IMPACT
- **Avant** : Suggestion basique de vectorisation
- **Apr√®s** : Solution compl√®te avec `np.select()`, comparaison de performance estim√©e (1000x plus rapide), alternative avec `pd.cut()` pour cat√©goriser, et code de benchmark

---

## Exemple 5 : Feature engineering sans direction

### ‚ùå AVANT
```
donne moi des id√©es de features pour mon mod√®le
```

### ‚ö†Ô∏è PROBL√àMES
- Type de probl√®me inconnu
- Donn√©es disponibles non sp√©cifi√©es
- Objectif m√©tier absent
- L'IA va donner des features g√©n√©riques et probablement non pertinentes

### ‚úÖ APR√àS
```markdown
## Contexte m√©tier
Pr√©diction du montant d'achat pour une campagne marketing e-commerce

## Donn√©es disponibles
**Historique client (12 mois)** :
- D√©mographiques : √¢ge, r√©gion, cat√©gorie socio-pro
- Comportement : nb visites/mois, temps sur site, nb pages vues
- Transactionnel : nb achats, montant total d√©pens√©, panier moyen
- Engagement : ouverture emails (oui/non), clics, nb produits en wishlist
- Temporel : date premi√®re visite, date dernier achat, anciennet√©

**Donn√©es produits** :
- Cat√©gories consult√©es (top 3)
- Produits achet√©s (avec prix et cat√©gorie)
- Produits abandonn√©s en panier

## Target
Montant d'achat dans les 30 prochains jours (r√©gression)

## Insights m√©tier
- Les clients qui r√©duisent leur fr√©quence d'achat tendent √† d√©penser moins
- Les achats sont tr√®s saisonniers (pics en fin de mois)
- La cat√©gorie "premium" a des patterns diff√©rents

## Question
Sugg√®re 15 features engineer√©es pertinentes qui capturent :
1. Les tendances comportementales (augmentation/baisse activit√©)
2. Les patterns temporels (saisonnalit√©, r√©cence)
3. Les signaux d'engagement
4. Les interactions entre variables

Pour chaque feature :
- Nom explicite
- Logique m√©tier
- Code Python (pandas/numpy)
- Hypoth√®se sur son pouvoir pr√©dictif
```

### üí° POURQUOI C'EST MIEUX
- Contexte m√©tier clair (e-commerce, pr√©diction montant)
- Donn√©es disponibles exhaustivement list√©es
- Type de probl√®me pr√©cis√© (r√©gression)
- Insights m√©tier partag√©s (aide l'IA √† contextualiser)
- Demande structur√©e avec crit√®res sp√©cifiques
- Format de r√©ponse attendu d√©fini

### üìä IMPACT
- **Avant** : Features g√©n√©riques (RFM, moyennes, etc.)
- **Apr√®s** : 15 features sur-mesure comme `purchase_acceleration`, `category_diversity_score`, `weekend_vs_weekday_ratio`, `days_since_last_premium_purchase`, avec code et justification m√©tier

---

## Exemple 6 : Explication de concept trop vague

### ‚ùå AVANT
```
c'est quoi la r√©gularisation ?
```

### ‚ö†Ô∏è PROBL√àMES
- Niveau de d√©tail inconnu (explication pour d√©butant ou expert ?)
- Contexte d'utilisation absent
- Type d'explication souhait√© non pr√©cis√© (th√©orique, pratique, code ?)

### ‚úÖ APR√àS
```markdown
## Contexte
Je suis en Master 1 Data Science, j'ai des bases en alg√®bre lin√©aire 
et en ML (r√©gression lin√©aire, logistique)

## Situation
J'impl√©mente un mod√®le de r√©gression Ridge pour pr√©dire des prix immobiliers.
Je comprends que Ridge utilise de la r√©gularisation, mais je n'ai pas 
l'intuition de comment √ßa fonctionne.

## Question
Peux-tu m'expliquer la r√©gularisation L2 (Ridge) :

1. **Intuition simple** : √Ä quoi √ßa sert concr√®tement ?
2. **Maths** : Formulation math√©matique (sans aller trop loin)
3. **Impact** : Comment √ßa modifie les coefficients du mod√®le ?
4. **Pratique** : 
   - Quand l'utiliser vs r√©gression lin√©aire simple ?
   - Comment choisir le param√®tre alpha ?
   - Exemple de code avec scikit-learn

5. **Comparaison** : Diff√©rence avec Lasso (L1) en quelques mots

Format : Progressif du simple au complexe, avec un exemple concret
```

### üí° POURQUOI C'EST MIEUX
- Niveau d'expertise pr√©cis√©
- Contexte d'utilisation concret (Ridge pour prix immobiliers)
- Questions structur√©es du g√©n√©ral au sp√©cifique
- Type d'explication souhait√© d√©taill√© (intuition + maths + pratique)
- Format de r√©ponse guid√©

### üìä IMPACT
- **Avant** : D√©finition g√©n√©rique de Wikipedia
- **Apr√®s** : Explication p√©dagogique en 5 niveaux adapt√©e au niveau Master, avec analogie (p√©naliser les coefficients trop grands = limiter l'overfitting), formule math√©matique, graphiques comparatifs, code pratique, et recommandations de param√©trage

---

## Exemple 7 : Visualisation sans sp√©cifications

### ‚ùå AVANT
```
fais moi un graphique pour ces donn√©es

ventes par r√©gion
```

### ‚ö†Ô∏è PROBL√àMES
- Type de graphique non sp√©cifi√©
- Structure des donn√©es inconnue
- Objectif de la visualisation absent
- Aucun crit√®re esth√©tique ou contrainte

### ‚úÖ APR√àS
~~~markdown
## Contexte
Pr√©sentation executive pour le comit√© de direction (non-technique)

## Donn√©es
DataFrame avec 3 ans de ventes par r√©gion :
```python
# Structure
   date       | region      | ventes_k‚Ç¨ | nb_clients
   2022-01-01 | Nord        | 1250      | 340
   2022-01-01 | Sud         | 980       | 275
   ...
```
- 12 r√©gions fran√ßaises
- Donn√©es mensuelles (36 mois)
- Ventes en milliers d'euros

## Objectif de la visualisation
Montrer l'√©volution temporelle des ventes ET comparer les r√©gions
pour identifier :
- Quelles r√©gions surperforment/sous-performent
- Les tendances temporelles (croissance, saisonnalit√©)
- Les r√©gions √† prioriser pour 2025

## Contraintes
- Doit √™tre compr√©hensible en 30 secondes
- Couleurs corporate : bleu (#1f77b4) et orange (#ff7f0e)
- Style moderne et professionnel
- Une seule visualisation (ou max 2 si compl√©mentaires)

## Question
Quel type de graphique recommandes-tu ?
G√©n√®re le code Python (matplotlib ou seaborn) avec :
- Titre et labels clairs
- L√©gende appropri√©e
- Annotations des points cl√©s si pertinent
~~~

### üí° POURQUOI C'EST MIEUX
- Audience clairement d√©finie (executives non-techniques)
- Structure des donn√©es explicit√©e avec exemple
- Objectif de la viz multidimensionnel
- Contraintes esth√©tiques et fonctionnelles
- Demande de recommandation + code

### üìä IMPACT
- **Avant** : Graphique en barres basique g√©n√©rique
- **Apr√®s** : Recommandation argument√©e (ex : small multiples ou heatmap temporelle), code complet avec style professionnel, annotations automatiques des insights cl√©s, et alternative avec visualisation interactive plotly

---

## Exemple 8 : Gestion de donn√©es manquantes

### ‚ùå AVANT
```
comment g√©rer les valeurs manquantes
```

### ‚ö†Ô∏è PROBL√àMES
- Type de donn√©es inconnu (num√©riques, cat√©gorielles, texte ?)
- Proportion de missing non pr√©cis√©e
- Pattern des manquants inconnu (MCAR, MAR, MNAR ?)
- Objectif final absent

### ‚úÖ APR√àS
```markdown
## Contexte du dataset
Donn√©es m√©dicales pour pr√©dire le risque de diab√®te

## Valeurs manquantes identifi√©es
Analyse avec `df.isnull().sum()` :
- `glucose` : 15% missing (num√©rique, crucial pour pr√©diction)
- `blood_pressure` : 8% missing (num√©rique, important)
- `bmi` : 5% missing (num√©rique, mod√©r√©)
- `insulin` : 48% missing (num√©rique, beaucoup !)
- `skin_thickness` : 30% missing (num√©rique)

## Observations
- Les missing sur `insulin` et `skin_thickness` semblent corr√©l√©s
- Certains patients ont TOUTES les valeurs, d'autres plusieurs manquantes
- Pattern : semble MAR (Missing At Random) - li√©s √† l'√¢ge des patients

## Objectif
Classification binaire (diab√®te oui/non) avec Random Forest

## Contraintes
- Dataset modeste : 768 lignes (pas √©norme)
- Besoin de garder un maximum de lignes
- Performances actuelles avec suppression des lignes : accuracy 72%

## Question
Quelle strat√©gie d'imputation recommandes-tu pour chaque variable ?
Options que je connais : moyenne, m√©diane, KNN, MICE...

Peux-tu :
1. Recommander une approche par variable
2. Justifier selon les caract√©ristiques (% missing, importance)
3. Donner le code Python (sklearn/pandas)
4. Expliquer l'impact sur la mod√©lisation
```

### üí° POURQUOI C'EST MIEUX
- Contexte m√©tier (donn√©es m√©dicales)
- Analyse d√©taill√©e des missing par variable
- Pattern des missing investigu√©
- Objectif de mod√©lisation pr√©cis√©
- Baseline performance donn√©e
- Demande structur√©e avec justifications attendues

### üìä IMPACT
- **Avant** : R√©ponse g√©n√©rique sur les m√©thodes d'imputation
- **Apr√®s** : Strat√©gie diff√©renci√©e par variable (ex : m√©diane pour BMI, KNN pour glucose, drop pour insulin vu le 48%, feature "insulin_missing" comme indicateur), code complet avec IterativeImputer, analyse de l'impact sur la performance, et warnings sur les biais potentiels

---

## Exemple 9 : D√©ploiement de mod√®le

### ‚ùå AVANT
```
comment d√©ployer mon mod√®le en production
```

### ‚ö†Ô∏è PROBL√àMES
- Type de mod√®le inconnu
- Infrastructure cible non pr√©cis√©e
- Contraintes de latence/volume absentes
- Niveau d'expertise en d√©ploiement inconnu

### ‚úÖ APR√àS
```markdown
## Contexte du mod√®le
Mod√®le XGBoost de d√©tection de fraude (classification binaire)
- Taille du mod√®le s√©rialis√© : 150 Mo
- Features : 45 (mixtes : num√©riques et cat√©gorielles encod√©es)
- Performance : recall 82%, precision 41%
- Framework : scikit-learn + XGBoost

## Infrastructure disponible
- Cloud : AWS (acc√®s complet)
- Base de donn√©es : PostgreSQL (transactions en temps r√©el)
- Stack backend actuel : Python 3.11, FastAPI
- Monitoring : DataDog disponible

## Contraintes
- **Latence critique** : < 100ms par pr√©diction
- **Volume** : ~5000 pr√©dictions/heure en pic
- **Disponibilit√©** : 99.9% SLA requis
- **Co√ªt** : Budget limit√© (√©viter instances trop ch√®res)

## Preprocessing requis
Quelques transformations avant inf√©rence :
- Encodage de 5 variables cat√©gorielles (OneHotEncoder fitted)
- Scaling de features num√©riques (StandardScaler fitted)
- Feature engineering (3 ratios calcul√©s)

## Mon niveau
Interm√©diaire en ML, d√©butant en MLOps/d√©ploiement

## Questions
1. Quelle architecture recommandes-tu ? (API REST, batch, streaming ?)
2. Comment g√©rer le preprocessing en production ?
3. Quel service AWS utiliser ? (Lambda, ECS, SageMaker ?)
4. Comment monitorer les pr√©dictions et d√©tecter le drift ?
5. Strat√©gie de versioning du mod√®le ?

Fournis une roadmap √©tape par √©tape avec exemples de code quand pertinent.
```

### üí° POURQUOI C'EST MIEUX
- Mod√®le compl√®tement d√©crit (type, taille, performance)
- Infrastructure et stack pr√©cis√©s
- Contraintes quantifi√©es (latence, volume, SLA)
- √âtapes de preprocessing list√©es
- Niveau d'expertise indiqu√©
- Questions structur√©es couvrant tous les aspects

### üìä IMPACT
- **Avant** : R√©ponse g√©n√©rale sur "il faut une API et Docker"
- **Apr√®s** : Architecture compl√®te (FastAPI + Docker + ECS), code de l'API avec preprocessing int√©gr√©, strat√©gie de monitoring avec m√©triques m√©tier (drift detection), plan de rollback, estimation de co√ªts AWS, et checklist de mise en production

---

## Exemple 10 : NLP - Classification de textes

### ‚ùå AVANT
```
comment classifier des textes en python
```

### ‚ö†Ô∏è PROBL√àMES
- Type de textes non pr√©cis√© (courts/longs, langue, domaine)
- Nombre de classes inconnu
- Volume de donn√©es absent
- Niveau de performance attendu non d√©fini

### ‚úÖ APR√àS
~~~markdown
## Contexte m√©tier
Classification automatique de tickets support client pour routage

## Donn√©es textuelles
- **Volume** : 50k tickets historiques d√©j√† labellis√©s
- **Langue** : Fran√ßais (France)
- **Longueur moyenne** : 50-200 mots (descriptions courtes)
- **Classes** : 5 cat√©gories
  - Technique (35%)
  - Facturation (25%)
  - Livraison (20%)
  - SAV (15%)
  - Autre (5%)
- **Exemples** :
```
  "Bonjour, je n'arrive pas √† me connecter √† mon compte 
  depuis ce matin, erreur 403"
  ‚Üí Cat√©gorie : Technique

  "Ma facture du mois dernier comporte des erreurs, 
  le montant ne correspond pas"
  ‚Üí Cat√©gorie : Facturation
  ```

## Contraintes
- **D√©ploiement** : API temps r√©el, latence < 500ms
- **Performances minimales** : accuracy > 85%, recall √©quilibr√© entre classes
- **Infrastructure** : Serveur 16 Go RAM, pas de GPU
- **√âvolution** : Mod√®le doit √™tre r√©entra√Ænable mensuellement

## Mon niveau
Bon en ML classique, d√©butant en NLP

## Questions
1. **Preprocessing** : Quelles √©tapes essentielles pour du texte fran√ßais ?
2. **Approche** : M√©thodes classiques (TF-IDF + classifieur) vs deep learning (transformers) ?
3. **Mod√®le** : Recommandation concr√®te avec justification
4. **Code** : Pipeline complet du preprocessing √† l'entra√Ænement
5. **Gestion du d√©s√©quilibre** : Comment g√©rer la classe "Autre" √† 5% ?

Format : Code Python comment√© √©tape par √©tape, avec explications p√©dagogiques
~~~

### üí° POURQUOI C'EST MIEUX
- Cas d'usage m√©tier clair (tickets support)
- Caract√©ristiques du corpus d√©taill√©es (volume, langue, longueur)
- Distribution des classes avec d√©s√©quilibre visible
- Exemples concrets de textes
- Contraintes de d√©ploiement et performance quantifi√©es
- Niveau d'expertise et attentes p√©dagogiques pr√©cis√©s
- Questions structur√©es couvrant tout le pipeline

### üìä IMPACT
- **Avant** : Tutoriel g√©n√©rique de classification de textes
- **Apr√®s** : Recommandation argument√©e (TF-IDF + Logistic Regression pour commencer, CamemBERT si besoin plus de performance), pipeline complet avec spaCy pour preprocessing fran√ßais, gestion du d√©s√©quilibre avec class_weight, code de validation crois√©e, baseline de performance, et comparaison co√ªt/b√©n√©fice deep learning vs classique

---

## üéì Patterns r√©currents observ√©s

### ‚úÖ Ce qui rend un prompt "APR√àS" meilleur

| Aspect | Caract√©ristique |
|--------|-----------------|
| **Contexte technique** | Versions, environnement, ressources pr√©cis√©es |
| **Donn√©es** | Taille, types, exemples fournis |
| **Objectif** | Clair, mesurable, avec crit√®res de succ√®s |
| **Contraintes** | Quantifi√©es (temps, m√©moire, latence) |
| **Tentatives** | Ce qui a d√©j√† √©t√© essay√© est document√© |
| **Structure** | Markdown avec sections logiques |
| **Sp√©cificit√©** | D√©tails concrets vs g√©n√©ralit√©s |
| **Format attendu** | Type de r√©ponse souhait√© explicit√© |

### ‚ùå Ce qui rend un prompt "AVANT" faible

| Probl√®me | Impact |
|----------|--------|
| Vague | R√©ponse g√©n√©rique inutilisable |
| Manque contexte | L'IA doit deviner, risque d'erreur |
| Pas de structure | Difficile √† parser, info noy√©e |
| Pas de chiffres | Impossible d'√©valuer l'√©chelle |
| Pas d'objectif clair | R√©ponse ne r√©pond pas au vrai besoin |
| Langage t√©l√©graphique | Perte de nuances importantes |
